{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_613/1548949676.py:37: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm, trange\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import time\n",
    "import sys\n",
    "import importlib\n",
    "import os\n",
    "import hashlib\n",
    "import subprocess\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "# from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import Dataset\n",
    "\n",
    "# from captum.attr import IntegratedGradients\n",
    "# from captum.attr import LayerConductance\n",
    "# from captum.attr import NeuronConductance\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "    \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "experiment_folder=\".\"\n",
    "all_ligs_db_file=f\"{experiment_folder}/all_ligands.pickle\"\n",
    "\n",
    "datafolder=f\"{experiment_folder}/cached_reprs\"\n",
    "\n",
    "# sys.path.append(experiment_folder)\n",
    "\n",
    "Bohr2Ang=0.529177249\n",
    "RT=0.001985875*300 #kcal/mol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Re)load Model and Dataset classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'NNs' in sys.modules:\n",
    "    importlib.reload(sys.modules['NNs'])\n",
    "else:\n",
    "    import NNs\n",
    "from NNs import *\n",
    "\n",
    "if 'computeDescriptors' in sys.modules:\n",
    "    importlib.reload(sys.modules['computeDescriptors'])\n",
    "else:\n",
    "    import computeDescriptors\n",
    "from computeDescriptors import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ligands and init Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "642 molecules with 6679 descriptors\n"
     ]
    }
   ],
   "source": [
    "with open(all_ligs_db_file, 'rb') as f:\n",
    "    ligs = pickle.load(f)\n",
    "    \n",
    "DB=CustomMolModularDataset(ligs)\n",
    "print(f\"{len(DB)} molecules with {DB[0][0].shape[0]} descriptors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove constant and highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of all data: (642, 6679)\n",
      "Variable (non-constant) features: 5180\n",
      "Highly correlated (>=0.8) features to remove: 1739\n",
      "Keapt features: 3441\n"
     ]
    }
   ],
   "source": [
    "allX=np.array([entry[0] for entry in DB])\n",
    "print(\"Shape of all data:\", allX.shape)\n",
    "\n",
    "# exclude features that are always constant\n",
    "keep_feature_indeces = np.where(np.logical_not(np.all(allX == allX[0,:], axis=0)))[0]\n",
    "print(f\"Variable (non-constant) features: {len(keep_feature_indeces)}\")\n",
    "\n",
    "\n",
    "# correlation\n",
    "cormat=np.corrcoef(allX[:,keep_feature_indeces].transpose())\n",
    "cormat -= np.tril(cormat) # remove self correlation and lower triangular\n",
    "cormat=np.abs(cormat) # absolute values\n",
    "\n",
    "# find any columns with high correlations\n",
    "cor_threshhold = 0.8\n",
    "high_cor_pairs = np.where(cormat>=cor_threshhold)\n",
    "to_remove = np.unique(high_cor_pairs[0]) # indeces to the keep_feature_indeces array\n",
    "print(f\"Highly correlated (>={cor_threshhold}) features to remove: {len(to_remove)}\")\n",
    "\n",
    "# WARNING/TODO: this removes features too agressively.\n",
    "# If feature B is corelated to A and C to B, but not C to A\n",
    "# this will remove both B and C.\n",
    "# Ideally if we remove B, we should retain C, but that requires more recursion\n",
    "\n",
    "# remove the correlated features\n",
    "keep_mask = np.ones(len(keep_feature_indeces), np.bool_)\n",
    "keep_mask[to_remove] = 0\n",
    "keep_feature_indeces = keep_feature_indeces[keep_mask]\n",
    "\n",
    "print(f\"Keapt features: {len(keep_feature_indeces)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinitialize dataset object without the removed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "642 molecules with 3441 descriptors remaining\n"
     ]
    }
   ],
   "source": [
    "DB=CustomMolModularDataset(ligs, X_filter=keep_feature_indeces)\n",
    "print(f\"{len(DB)} molecules with {DB[0][0].shape[0]} descriptors remaining\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normalize_x=True\n",
    "shuffle_seed=12345678\n",
    "\n",
    "#n_Epochs=2000\n",
    "#hl_w=300\n",
    "#hl_depth=2\n",
    "\n",
    "n_Epochs=200\n",
    "hl_w=20\n",
    "hl_depth=1\n",
    "\n",
    "init_learning_rate=5e-3\n",
    "learning_rate_decay=10000 #order of magnitude in this many epochs\n",
    "weight_decay=1e-3\n",
    "\n",
    "normalize_x=True\n",
    "X_filter=None\n",
    "impfilt=None\n",
    "\n",
    "weighted=True\n",
    "use_dropout=True\n",
    "shiftY=True\n",
    "\n",
    "redo=False\n",
    "\n",
    "batchsize=100\n",
    "eval_batchsize=200\n",
    "activation=\"relu\"\n",
    "\n",
    "eval_every=min(10, n_Epochs)\n",
    "plot_every=min(1000, n_Epochs)\n",
    "backup_models_every=1000\n",
    "\n",
    "normalize_x=True\n",
    "predict_all_ligs=True\n",
    "\n",
    "save_folder=\"models/Perceptron\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found normalization factors across all ligands 2023-11-17 00:15:42.647392\n",
      "Will save models in:\n",
      "\t models/Perceptron\n"
     ]
    }
   ],
   "source": [
    "allYdata=(np.array([float(lig.GetProp('dG')) for lig in ligs]))\n",
    "minY=np.min(allYdata)\n",
    "maxY=np.max(allYdata)\n",
    "\n",
    "    #shuffle ligand indeces\n",
    "all_idxs_shuffled=np.arange(len(ligs))\n",
    "np.random.seed(shuffle_seed)\n",
    "np.random.shuffle(all_idxs_shuffled) # in place transform\n",
    "\n",
    "\n",
    "if(X_filter is not None):\n",
    "    if(not os.path.exists(X_filter)):\n",
    "        raise(Exception(f\"No such file: {X_filter}\"))\n",
    "        \n",
    "if(weighted):\n",
    "    kde = sp.stats.gaussian_kde(allYdata)\n",
    "    temp_Y=np.linspace(np.min(allYdata), np.max(allYdata), 20, endpoint=True)\n",
    "    temp_kde=kde(temp_Y)\n",
    "    C=1/np.mean(1/temp_kde)\n",
    "    def get_weights(y):\n",
    "        return(C/kde(y))\n",
    "    weight_func=get_weights\n",
    "\n",
    "    ###################debug###################\n",
    "    #weights=weight_func(temp_Y)\n",
    "    #print(temp_Y)\n",
    "    #print(weights)\n",
    "    #plt.plot(temp_Y, weights)\n",
    "    #plt.show()\n",
    "    #raise()\n",
    "    ###################debug###################\n",
    "else:\n",
    "    weight_func=None\n",
    "\n",
    "if(use_dropout):\n",
    "    p_dropout=np.repeat(0.5, hl_depth+1)\n",
    "else:\n",
    "    p_dropout=np.repeat(0.0, hl_depth+1)\n",
    "\n",
    "noise=0.0\n",
    "\n",
    "train_clr=\"blue\"\n",
    "Xval_clr=\"purple\"\n",
    "unkn_clr=\"green\"\n",
    "summary_train_clr=\"darkred\"\n",
    "summary_unkn_clr=\"peru\"\n",
    "\n",
    "\n",
    "#generator for all data\n",
    "full_dataset = DB\n",
    "\n",
    "if(normalize_x):\n",
    "    full_dataset.find_normalization_factors()\n",
    "    print(\"Found normalization factors across all ligands\", datetime.now(), flush=True)\n",
    "if(predict_all_ligs):\n",
    "    all_generator = torch.utils.data.DataLoader(full_dataset, shuffle=False, batch_size=eval_batchsize)\n",
    "    \n",
    "multi_model_record=None\n",
    "global_models=None\n",
    "global_summary_model=None\n",
    "\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "save_plot=save_folder+f\"/summary_ep_{n_Epochs}.png\"\n",
    "print(\"Will save models in:\\n\\t\", save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
